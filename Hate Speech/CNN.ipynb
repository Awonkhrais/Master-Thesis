{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import preprocess_kgptalkie as ps\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "##########################\n",
    "df = pd.read_csv('labeled_data.csv',index_col=0)\n",
    "df\n",
    "##########################\n",
    "vc = df['class'].value_counts()\n",
    "index = list(vc.index)\n",
    "count = min(vc.values)\n",
    "df_bal = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "for i in index:\n",
    "    temp = df[df['class'] == i].sample(count)\n",
    "    df_bal = pd.concat([df_bal, temp], ignore_index=True)\n",
    "\n",
    "df = df_bal.copy()\n",
    "df\n",
    "##########################\n",
    "labels = df['class'].value_counts().index.tolist()\n",
    "values = df['class'].value_counts().values.tolist()\n",
    "new_labels = []\n",
    "\n",
    "for index, label in enumerate(labels):\n",
    "    if label == 0:\n",
    "        new_labels.append(\"Hate speech\")\n",
    "    elif label == 1:\n",
    "        new_labels.append(\"Offensive language\")\n",
    "    else:\n",
    "        new_labels.append(\"Neither\")\n",
    "\n",
    "plt.pie(values, labels=new_labels, autopct='%1.1f%%')\n",
    "plt.show()\n",
    "##########################\n",
    "from bs4 import BeautifulSoup\n",
    "def remove_html_tags(x):\n",
    "    return BeautifulSoup(x, 'html.parser').get_text().strip()\n",
    "def get_clean(x):\n",
    "    x = str(x).lower().replace('\\\\', '').replace('_', ' ')\n",
    "    x = ps.cont_exp(x)\n",
    "    x = ps.remove_emails(x)\n",
    "    x = ps.remove_urls(x)\n",
    "    x = ps.remove_rt(x)\n",
    "    x = ps.remove_accented_chars(x)\n",
    "    x = ps.remove_special_chars(x)\n",
    "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "    return x\n",
    "df['tweet'] = df['tweet'].apply(lambda x: remove_html_tags(x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: get_clean(x))\n",
    "##########################\n",
    "# convert our text data in form of list\n",
    "text = df['tweet'].tolist()\n",
    "# transfer each text in texts to a sequeance of integer\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "vocab_size = len(token.word_counts) + 1\n",
    "encoded_text = token.texts_to_sequences(text)\n",
    "print(encoded_text)\n",
    "\n",
    "max_length = 120\n",
    "X = pad_sequences(encoded_text, maxlen=max_length, padding = 'post')\n",
    "y = df['class']\n",
    "y = np_utils.to_categorical(df['class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "X_train.shape, X_test.shape\n",
    "vec_size = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_length))\n",
    "\n",
    "model.add(Conv1D(32, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history=model.fit(X_train, y_train, epochs = 2, validation_data=(X_test, y_test), shuffle = True)\n",
    "# Evaluate CNN model accuracy\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "plot_confusion_matrix(confusion_matrix(np.argmax(y_test, axis=-1), y_pred))\n",
    "print(classification_report(np.argmax(y_test, axis=-1), y_pred))\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define class labels\n",
    "class_labels = [\"Hate\", \"Offensive\", \"Neither\"]\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=-1), y_pred)\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else '.0f'  # Format as decimal fraction if normalize=True\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(cm, classes=class_labels, normalize=True)  # Set normalize=True to display decimal fractions\n",
    "plt.show()\n",
    "\n",
    "# Training Results\n",
    "\n",
    "# Get predictions for training set\n",
    "y_train_pred = np.argmax(model.predict(X_train), axis=-1)\n",
    "\n",
    "# Calculate training set accuracy\n",
    "train_accuracy = accuracy_score(np.argmax(y_train, axis=-1), y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(np.argmax(y_train, axis=-1), y_train_pred)\n",
    "print(\"Training Classification Report:\")\n",
    "print(train_report)\n",
    "\n",
    "\n",
    "# Generate confusion matrix for training set\n",
    "\n",
    "# Define class labels\n",
    "class_labels = [\"Hate\", \"Offensive\", \"Neither\"]\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_train_pred = np.argmax(model.predict(X_train), axis=-1)\n",
    "train_cm = confusion_matrix(np.argmax(y_train, axis=-1), y_train_pred)\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(train_cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        train_cm = train_cm.astype('float') / train_cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(train_cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else '.0f'  # Format as decimal fraction if normalize=True\n",
    "    thresh = train_cm.max() / 2.\n",
    "    for i, j in itertools.product(range(train_cm.shape[0]), range(train_cm.shape[1])):\n",
    "        plt.text(j, i, format(train_cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if train_cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(train_cm, classes=class_labels, normalize=True)  # Set normalize=True to display decimal fractions\n",
    "plt.show()\n",
    "\n",
    "# Classification Hate & Offensive to 3 levels\n",
    "\n",
    "# Define offensive words and their corresponding offensive levels\n",
    "offensive_words = {\n",
    "    'very_offensive': ['abortion', 'ass', 'bastard', 'bitch', 'cunt', 'damn', 'faggot', 'nigger', 'rape', 'slut', 'whore', 'white power', 'you suck', 'shut up', 'suck my dick', 'suck it', 'fuck you', 'fuck off', 'go to hell', 'die'],\n",
    "    'moderately_offensive': ['idiot', 'moron', 'retard', 'stupid', 'dumb', 'loser', 'gay', 'ugly', 'fat', 'douchebag', 'creep', 'pussy', 'dick', 'piss off', 'leave me alone', 'get lost', 'not interested', 'no thanks', 'whatever', 'who cares'],\n",
    "    'little_offensive': ['jerk', 'fool', 'wimp', 'weenie', 'dork', 'nerd', 'geek', 'awkward', 'weird', 'annoying', 'bothersome', 'irritating', 'hate', 'dislike', 'boring', 'tedious', 'not fun', 'blah', 'whatever', 'meh']\n",
    "}\n",
    "\n",
    "# Define hate speech words and their corresponding hate speech levels\n",
    "hate_speech_words = {\n",
    "    'danger_hate_speech': ['kill', 'hate', 'racist', 'terrorist', 'genocide','niggah','nigger', 'exterminate', 'eliminate', 'eradicate', 'annihilate', 'lynch', 'hang', 'burn', 'shoot', 'murder', 'rape'],\n",
    "    'moderately_hate_speech': ['bigot', 'prejudice', 'homophobia', 'islamophobia', 'antisemitism', 'discrimination', 'intolerance', 'hatred', 'hostility', 'oppression', 'supremacist', 'nationalist', 'segregation', 'separatism'],\n",
    "    'poor_hate_speech': ['offend', 'disrespect', 'insult', 'belittle', 'mock', 'ridicule', 'scorn', 'taunt', 'tease', 'joke', 'laugh', 'smear', 'troll', 'bully', 'harass', 'threaten']\n",
    "}\n",
    "\n",
    "def classify_Hate_tweet(tweet, label, hate_speech_words):\n",
    "    if label == 0:\n",
    "        for level, words in hate_speech_words.items():\n",
    "            for word in words:\n",
    "                if word in tweet.lower():\n",
    "                    if level == 'danger_hate_speech':\n",
    "                        return level, \"Block account completely\"\n",
    "                    elif level == 'moderately_hate_speech':\n",
    "                        return level, \"Block account for a while\"\n",
    "                    elif level == 'poor_hate_speech':\n",
    "                        return level, \"Send a reminder\"\n",
    "        return 'Not a hate speech tweet', None  # Return None for action if no match is found\n",
    "\n",
    "def classify_Off_tweet(tweet, label, offensive_words):\n",
    "    if label == 1:\n",
    "        for level, words in offensive_words.items():\n",
    "            for word in words:\n",
    "                if word in tweet.lower():\n",
    "                    if level == 'very_offensive':\n",
    "                        return level, \"Remove account\"\n",
    "                    elif level == 'moderately_offensive':\n",
    "                        return level, \"Block the ability to edit posts\"\n",
    "                    elif level == 'little_offensive':\n",
    "                        return level, \"Block account for a while\"\n",
    "        return 'Not an offensive tweet', None  # Return None for action if no match is found\n",
    "    \n",
    "##########################\n",
    "\n",
    "# Testing with custom date\n",
    "\n",
    "def get_encoded(x):\n",
    "  x = remove_html_tags(x)\n",
    "  x = get_clean(x)\n",
    "  x = token.texts_to_sequences([x])\n",
    "  x = pad_sequences(x, maxlen=max_length, padding = 'post')\n",
    "  return x\n",
    "\n",
    "\n",
    "np.argmax(model.predict(get_encoded(x)), axis=-1)\n",
    "result = np.argmax(model.predict(get_encoded(x)), axis=-1)[0]\n",
    "print(result)\n",
    "\n",
    "\n",
    "hate_speech_result = classify_Hate_tweet(x, result, hate_speech_words)\n",
    "offensive_result = classify_Off_tweet(x, result, offensive_words)\n",
    "\n",
    "if hate_speech_result is not None:\n",
    "    hate_speech_level, hate_speech_action = hate_speech_result\n",
    "    print(\"Hate Speech Level:\", hate_speech_level)\n",
    "    print(\"Action to Take:\", hate_speech_action)\n",
    "\n",
    "if offensive_result is not None and offensive_result[0] != 'Not an offensive tweet':\n",
    "    offensive_level, offensive_action = offensive_result\n",
    "    print(\"Offensive Level:\", offensive_level)\n",
    "    print(\"Action to Take:\", offensive_action)\n",
    "\n",
    "if hate_speech_result is None and (offensive_result is None or offensive_result[0] == 'Not an offensive tweet'):\n",
    "    print(\"No action needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18b165f1ae57c390c96e80c3deb3553371e1a95d7bfc065943e63e3bb76ac6a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
